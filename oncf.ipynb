{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df0335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def scrape_trips(origin,destination,date):\n",
    "    url = 'https://www.oncf-voyages.ma:8443/availability'\n",
    "    headers_str = '''Accept: application/json, text/plain, */*\n",
    "    Accept-Encoding: gzip, deflate, br\n",
    "    Accept-Language: en-FR,en;q=0.9,fr-FR;q=0.8,fr;q=0.7,en-US;q=0.6\n",
    "    Connection: keep-alive\n",
    "    Content-Length: 359\n",
    "    Content-Type: application/json\n",
    "    Host: www.oncf-voyages.ma:8443\n",
    "    Origin: https://www.oncf-voyages.ma\n",
    "    Referer: https://www.oncf-voyages.ma/\n",
    "    Sec-Fetch-Dest: empty\n",
    "    Sec-Fetch-Mode: cors\n",
    "    Sec-Fetch-Site: same-site\n",
    "    User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\n",
    "    X-XSRF-TOKEN: null\n",
    "    sec-ch-ua: \"Google Chrome\";v=\"111\", \"Not(A:Brand\";v=\"8\", \"Chromium\";v=\"111\"\n",
    "    sec-ch-ua-mobile: ?0\n",
    "    sec-ch-ua-platform: \"Windows\"'''\n",
    "    # Split the headers into a dictionary\n",
    "    headers_dict = {}\n",
    "    for header in headers_str.split('\\n'):\n",
    "        if ':' in header:\n",
    "            key, value = header.split(': ', 1)\n",
    "            headers_dict[key.strip()] = value.strip()\n",
    "    # Define the raw body\n",
    "    body = '{\"origin\":\"'+origin+'\",\"destination\":\"'+destination+'\",\"originDate\":\"'+date+'T00:01:13+00:00\",\"intervalTime\":\"\",\"adulte\":1,\"kids\":0,\"comfort\":2,\"reducedTariff\":{\"0\":{\"code\":\"\",\"priceCode\":\"\",\"birthday\":\"\",\"claimCode\":\"\"}},\"destinationDate\":null,\"intervalTime-originDate\":{\"end\":\"06:00\",\"start\":\"00:01\",\"title\":\"Nuit\",\"value\":0,\"disabled\":false},\"roundtrip\":false,\"_csrf\":null}'\n",
    "    # Send the POST request with the raw headers and body\n",
    "    response = requests.post(url, headers=headers_dict, data=body)\n",
    "    return response.content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e24468b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>station_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>796</td>\n",
       "      <td>ADDAKHLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190</td>\n",
       "      <td>AEROPORT Med V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>745</td>\n",
       "      <td>AGADIR  (SUPRAT.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>832</td>\n",
       "      <td>AGDZ (SUPRAT.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>884</td>\n",
       "      <td>AIN DEFALI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>413</td>\n",
       "      <td>TOUABAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>77</td>\n",
       "      <td>YOUSSOUFIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>762</td>\n",
       "      <td>ZAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>834</td>\n",
       "      <td>ZAGORA (SUPRAT.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>816</td>\n",
       "      <td>ZAOUIAT CHEHCH (SUPRAT.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id              station_name\n",
       "0    796                  ADDAKHLA\n",
       "1    190            AEROPORT Med V\n",
       "2    745         AGADIR  (SUPRAT.)\n",
       "3    832            AGDZ (SUPRAT.)\n",
       "4    884                AIN DEFALI\n",
       "..   ...                       ...\n",
       "141  413                   TOUABAA\n",
       "142   77                YOUSSOUFIA\n",
       "143  762                       ZAG\n",
       "144  834          ZAGORA (SUPRAT.)\n",
       "145  816  ZAOUIAT CHEHCH (SUPRAT.)\n",
       "\n",
       "[146 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loads data for stations & their respective ids\n",
    "stations=pd.read_csv('stations.csv')\n",
    "stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac7d9358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "#This takes a list of stations you want to scrape and creates every possible combination of pairs.\n",
    "\n",
    "stations_list=['Casa Oasis','FES','RABAT VILLE','TANGER VILLE','MARRAKECH',\n",
    "                                       'AGADIR  (SUPRAT.)','SALE','LAAYOUNE']\n",
    "\n",
    "ids_list=list(stations[stations['station_name'].isin(stations_list)].id)\n",
    "ids_combinations=list(combinations(ids_list, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcde2221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_date_array(start_date_str, end_date_str):\n",
    "    \"\"\"\n",
    "    Generates an array of dates from start date to end date to be used on the request for trips\n",
    "    \"\"\"\n",
    "    start_date = datetime.datetime.strptime(start_date_str, \"%Y-%m-%d\").date()\n",
    "    end_date = datetime.datetime.strptime(end_date_str, \"%Y-%m-%d\").date()\n",
    "\n",
    "    delta = datetime.timedelta(days=1)\n",
    "\n",
    "    date_array = []\n",
    "\n",
    "    while start_date <= end_date:\n",
    "        date_array.append(start_date.strftime(\"%Y-%m-%d\"))\n",
    "        start_date += delta\n",
    "\n",
    "    return date_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaced446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023-04-07',\n",
       " '2023-04-08',\n",
       " '2023-04-09',\n",
       " '2023-04-10',\n",
       " '2023-04-11',\n",
       " '2023-04-12',\n",
       " '2023-04-13',\n",
       " '2023-04-14',\n",
       " '2023-04-15',\n",
       " '2023-04-16',\n",
       " '2023-04-17',\n",
       " '2023-04-18',\n",
       " '2023-04-19',\n",
       " '2023-04-20',\n",
       " '2023-04-21',\n",
       " '2023-04-22',\n",
       " '2023-04-23']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chage dates according to your needs\n",
    "start_date = \"2023-04-07\"\n",
    "end_date = \"2023-04-23\"\n",
    "dates = generate_date_array(start_date, end_date)\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "488396f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]\n",
      "  0%|                                                                                           | 0/17 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|████▉                                                                              | 1/17 [00:03<00:48,  3.05s/it]\u001b[A\n",
      " 12%|█████████▊                                                                         | 2/17 [00:06<00:49,  3.33s/it]\u001b[A\n",
      " 18%|██████████████▋                                                                    | 3/17 [00:09<00:45,  3.28s/it]\u001b[A\n",
      " 24%|███████████████████▌                                                               | 4/17 [00:13<00:44,  3.40s/it]\u001b[A\n",
      " 29%|████████████████████████▍                                                          | 5/17 [00:16<00:39,  3.31s/it]\u001b[A\n",
      " 35%|█████████████████████████████▎                                                     | 6/17 [00:28<01:09,  6.33s/it]\u001b[A\n",
      " 41%|██████████████████████████████████▏                                                | 7/17 [00:31<00:53,  5.33s/it]\u001b[A\n",
      " 47%|███████████████████████████████████████                                            | 8/17 [00:35<00:41,  4.61s/it]\u001b[A\n",
      " 53%|███████████████████████████████████████████▉                                       | 9/17 [00:38<00:33,  4.19s/it]\u001b[A\n",
      " 59%|████████████████████████████████████████████████▏                                 | 10/17 [00:50<00:46,  6.67s/it]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████████                             | 11/17 [00:53<00:33,  5.56s/it]\u001b[A\n",
      " 71%|█████████████████████████████████████████████████████████▉                        | 12/17 [00:56<00:24,  4.84s/it]\u001b[A\n",
      " 76%|██████████████████████████████████████████████████████████████▋                   | 13/17 [00:58<00:15,  3.99s/it]\u001b[A\n",
      " 82%|███████████████████████████████████████████████████████████████████▌              | 14/17 [01:00<00:10,  3.39s/it]\u001b[A\n",
      " 88%|████████████████████████████████████████████████████████████████████████▎         | 15/17 [01:02<00:05,  2.99s/it]\u001b[A\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████▏    | 16/17 [01:06<00:03,  3.03s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [01:09<00:00,  4.06s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:09<00:00, 69.02s/it]\n"
     ]
    }
   ],
   "source": [
    "#This is the main scraping block it uses previous functions to scrape the data and saves it to responses.csv\n",
    "\n",
    "pd.DataFrame({\"origin\":[],\"destination\":[],\"response\":[]}).to_csv('responses.csv',index=False)\n",
    "for combination in tqdm(ids_combinations):\n",
    "    origin=str(combination[0])\n",
    "    destination=str(combination[1])\n",
    "    for date in tqdm(dates):\n",
    "        responses=[]\n",
    "        origins=[]\n",
    "        destinations=[]\n",
    "        origins.append(origin)\n",
    "        destinations.append(destination)\n",
    "        response=scrape_trips(origin,destination,date)\n",
    "        responses.append(response.decode('utf-8'))\n",
    "        pd.DataFrame({\"origin\":origins,\"destination\":destinations,\"response\":responses}).to_csv('responses.csv', mode='a',index=False, header=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a9f7094",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf=pd.read_csv(\"responses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4d14c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Raw responses are hard to work with this function extracts useful information from a response\n",
    "def process_response(response):\n",
    "    \n",
    "    data = json.loads(response)\n",
    "    dateTimeDepartures=[]\n",
    "    dateTimeArrivals=[]\n",
    "    journeyDurations=[]\n",
    "    expresses=[]\n",
    "    type_trips=[]\n",
    "    price_trips=[]\n",
    "    price_sup_trips=[]\n",
    "    departureStationIds=[]\n",
    "    arrivalStationIds=[]\n",
    "    for path in data['availability']['departurePath']:\n",
    "        dateTimeDeparture=path['dateTimeDeparture']\n",
    "        dateTimeArrival=path['dateTimeArrival']\n",
    "        journeyDuration=path['journeyDuration']\n",
    "        journeyDuration=path['journeyDuration']\n",
    "        departureStationId=path['departureStationId']['description']['default']\n",
    "        arrivalStationId=path['arrivalStationId']['description']['default']\n",
    "        \n",
    "        express=path['express']\n",
    "        tripPrices=path['tripPrices']\n",
    "        for price in tripPrices[1:]:\n",
    "            type_trip=price['type']\n",
    "            price_trip=price['data']['price']\n",
    "            price_sup_trip=price['data']['priceSup']\n",
    "            dateTimeDepartures.append(dateTimeDeparture)\n",
    "            dateTimeArrivals.append(dateTimeArrival)\n",
    "            journeyDurations.append(journeyDuration)\n",
    "            expresses.append(express)\n",
    "            type_trips.append(type_trip)\n",
    "            price_trips.append(price_trip)\n",
    "            price_sup_trips.append(price_sup_trip)\n",
    "            departureStationIds.append(departureStationId)\n",
    "            arrivalStationIds.append(arrivalStationId)\n",
    "            \n",
    "    return pd.DataFrame({'dateTimeDeparture':dateTimeDepartures,'dateTimeArrival':dateTimeArrivals,'journeyDuration':journeyDurations,\n",
    "             'express':expresses,'type_trip':type_trips,'price_trip':price_trips,'price_sup_trip':price_sup_trips,\n",
    "                        'departureStationId':departureStationIds,'arrivalStationId':arrivalStationIds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e640ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function applies the processing to all responses and augments the data with distance between cities\n",
    "#Be careful the hard coded distances array should correspond to order of cities\n",
    "#If you get error relating to distance proprety, remove it and start analysis without it\n",
    "\n",
    "def process_responses(responses):\n",
    "    result_df=pd.DataFrame()\n",
    "    for response in responses:\n",
    "        try:\n",
    "            df=process_response(response)\n",
    "            result_df = pd.concat([result_df, df], ignore_index=True)\n",
    "        except:\n",
    "            continue\n",
    "    result_df=result_df.drop_duplicates()\n",
    "    ditances_dict=result_df[['departureStationId', 'arrivalStationId']].drop_duplicates()\n",
    "    ditances_dict['distance']=[460.2,754.8,547.4,555,798.6,299,926.3,241.6,342.8,1375,532,207.1,193,305,322.9,291,574,251,238.3,73]\n",
    "    result_df['dateTimeDeparture'] = pd.to_datetime(result_df['dateTimeDeparture'])\n",
    "    result_df['dateTimeArrival'] = pd.to_datetime(result_df['dateTimeArrival'])\n",
    "    result_df['day_name'] = result_df['dateTimeDeparture'].dt.day_name()\n",
    "    result_df=result_df[result_df['type_trip']=='Semi Flex']\n",
    "    result_df['hour_departure'] = result_df['dateTimeDeparture'].dt.hour\n",
    "    result_df['hour_arrival'] = result_df['dateTimeArrival'].dt.hour\n",
    "    result_df['days_from_earliest']=result_df['dateTimeDeparture'].apply(lambda x: (x - pd.Timestamp('2023-04-06 16:44:00', tz='UTC')).days)\n",
    "    result_df['min_price']=result_df[['departureStationId','arrivalStationId']].apply(lambda x: result_df[(result_df['departureStationId']==x['departureStationId']) & (result_df['arrivalStationId']==x['arrivalStationId'])]['price_trip'].min(), axis=1)\n",
    "    result_df['max_price']=result_df[['departureStationId','arrivalStationId']].apply(lambda x: result_df[(result_df['departureStationId']==x['departureStationId']) & (result_df['arrivalStationId']==x['arrivalStationId'])]['price_trip'].max(), axis=1)\n",
    "\n",
    "    result_df['diff_from_min']=((result_df['price_trip']-result_df['min_price'])/result_df['min_price'])*100\n",
    "    return pd.merge(result_df, ditances_dict, on=['departureStationId', 'arrivalStationId'])\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d503fb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_processed=process_responses(outdf.response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
